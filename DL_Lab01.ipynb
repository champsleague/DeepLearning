{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEUFjyISiKvkGZPbaZYEBa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/champsleague/DeepLearning/blob/main/DL_Lab01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p39q-crCWenv",
        "outputId": "15e45fea-c7e6-4f7d-b5dd-6b8a2b83a2f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:0 cost: 4653.625000\n",
            "Epoch:1 cost: 98.389252\n",
            "Epoch:2 cost: 94.882988\n",
            "Epoch:3 cost: 94.879570\n",
            "Epoch:4 cost: 94.878838\n",
            "Epoch:5 cost: 94.878075\n",
            "Epoch:6 cost: 94.877319\n",
            "Epoch:7 cost: 94.876564\n",
            "Epoch:8 cost: 94.875870\n",
            "Epoch:9 cost: 94.875114\n",
            "Epoch:10 cost: 94.874390\n",
            "Epoch:11 cost: 94.873680\n",
            "Epoch:12 cost: 94.872902\n",
            "Epoch:13 cost: 94.872177\n",
            "Epoch:14 cost: 94.871429\n",
            "Epoch:15 cost: 94.870697\n",
            "Epoch:16 cost: 94.870003\n",
            "Epoch:17 cost: 94.869240\n",
            "Epoch:18 cost: 94.868515\n",
            "Epoch:19 cost: 94.867783\n",
            "Epoch:20 cost: 94.867035\n",
            "Epoch:21 cost: 94.866280\n",
            "Epoch:22 cost: 94.865555\n",
            "Epoch:23 cost: 94.864799\n",
            "Epoch:24 cost: 94.864105\n",
            "Epoch:25 cost: 94.863396\n",
            "Epoch:26 cost: 94.862610\n",
            "Epoch:27 cost: 94.861870\n",
            "Epoch:28 cost: 94.861107\n",
            "Epoch:29 cost: 94.860382\n",
            "Epoch:30 cost: 94.859619\n",
            "Epoch:31 cost: 94.858948\n",
            "Epoch:32 cost: 94.858223\n",
            "Epoch:33 cost: 94.857452\n",
            "Epoch:34 cost: 94.856735\n",
            "Epoch:35 cost: 94.855942\n",
            "Epoch:36 cost: 94.855247\n",
            "Epoch:37 cost: 94.854500\n",
            "Epoch:38 cost: 94.853783\n",
            "Epoch:39 cost: 94.853065\n",
            "Epoch:40 cost: 94.852295\n",
            "Epoch:41 cost: 94.851593\n",
            "Epoch:42 cost: 94.850807\n",
            "Epoch:43 cost: 94.850121\n",
            "Epoch:44 cost: 94.849335\n",
            "Epoch:45 cost: 94.848618\n",
            "Epoch:46 cost: 94.847862\n",
            "Epoch:47 cost: 94.847130\n",
            "Epoch:48 cost: 94.846451\n",
            "Epoch:49 cost: 94.845695\n",
            "Epoch:50 cost: 94.844971\n",
            "Epoch:51 cost: 94.844200\n",
            "Epoch:52 cost: 94.843498\n",
            "Epoch:53 cost: 94.842705\n",
            "Epoch:54 cost: 94.842018\n",
            "Epoch:55 cost: 94.841248\n",
            "Epoch:56 cost: 94.840515\n",
            "Epoch:57 cost: 94.839775\n",
            "Epoch:58 cost: 94.839050\n",
            "Epoch:59 cost: 94.838318\n",
            "Epoch:60 cost: 94.837578\n",
            "Epoch:61 cost: 94.836891\n",
            "Epoch:62 cost: 94.836128\n",
            "Epoch:63 cost: 94.835396\n",
            "Epoch:64 cost: 94.834610\n",
            "Epoch:65 cost: 94.833916\n",
            "Epoch:66 cost: 94.833145\n",
            "Epoch:67 cost: 94.832443\n",
            "Epoch:68 cost: 94.831688\n",
            "Epoch:69 cost: 94.830956\n",
            "Epoch:70 cost: 94.830231\n",
            "Epoch:71 cost: 94.829514\n",
            "Epoch:72 cost: 94.828773\n",
            "Epoch:73 cost: 94.828026\n",
            "Epoch:74 cost: 94.827316\n",
            "Epoch:75 cost: 94.826546\n",
            "Epoch:76 cost: 94.825798\n",
            "Epoch:77 cost: 94.825066\n",
            "Epoch:78 cost: 94.824348\n",
            "Epoch:79 cost: 94.823593\n",
            "Epoch:80 cost: 94.822861\n",
            "Epoch:81 cost: 94.822113\n",
            "Epoch:82 cost: 94.821419\n",
            "Epoch:83 cost: 94.820709\n",
            "Epoch:84 cost: 94.819954\n",
            "Epoch:85 cost: 94.819221\n",
            "Epoch:86 cost: 94.818459\n",
            "Epoch:87 cost: 94.817757\n",
            "Epoch:88 cost: 94.816971\n",
            "Epoch:89 cost: 94.816292\n",
            "Epoch:90 cost: 94.815521\n",
            "Epoch:91 cost: 94.814789\n",
            "Epoch:92 cost: 94.814034\n",
            "Epoch:93 cost: 94.813339\n",
            "Epoch:94 cost: 94.812576\n",
            "Epoch:95 cost: 94.811859\n",
            "Epoch:96 cost: 94.811089\n",
            "Epoch:97 cost: 94.810394\n",
            "Epoch:98 cost: 94.809624\n",
            "Epoch:99 cost: 94.808937\n",
            "\n",
            "\n",
            "tensor([0.9679], requires_grad=True)\n",
            "tensor([0.0404], requires_grad=True)\n",
            "Final score is estimated as 68\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "\n",
        "# define parameters : W:weigh, b:bias\n",
        "W = torch.zeros(1, requires_grad = True)\n",
        "b = torch.zeros(1, requires_grad = True)\n",
        "\n",
        "x_train = torch.FloatTensor([[78],[83],[56],[67],[85],[44],[32],[90]])\n",
        "y_train = torch.FloatTensor([[66],[73],[76],[65],[81],[54],[29],[85]])\n",
        "\n",
        "optimizer = optim.SGD([W,b],lr=0.0001)\n",
        "\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "  hypothesis = x_train * W + b\n",
        "  cost = torch.mean((hypothesis-y_train)**2)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  print('Epoch:%d cost: %f'%(epoch,cost))\n",
        "\n",
        "\n",
        "# test\n",
        "print('\\n')\n",
        "print(W)\n",
        "print(b)\n",
        "predict = W * 71 + b\n",
        "print('Final score is estimated as %d' % (predict))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "\n",
        "# define parameters : W:weigh, b:bias\n",
        "W1 = torch.zeros(1, requires_grad = True)\n",
        "b1 = torch.zeros(1, requires_grad = True)\n",
        "\n",
        "W2 = torch.zeros(1, requires_grad = True)\n",
        "W3 = torch.zeros(1, requires_grad = True)\n",
        "W4 = torch.zeros(1, requires_grad = True)\n",
        "\n",
        "x_GPA = torch.FloatTensor([[3.8],[3.2],[3.7],[4.2],[2.6],[3.4],[4.1],[3.3],[3.9]])\n",
        "x_TOEIC = torch.FloatTensor([[700],[650],[820],[830],[550],[910],[990],[870],[650]])\n",
        "x_Award = torch.FloatTensor([[80],[90],[70],[50],[90],[30],[70],[60],[80]])\n",
        "x_Etc = torch.FloatTensor([[50],[30],[40],[70],[60],[40],[20],[60],[50]])\n",
        "y_train = torch.FloatTensor([[85],[80],[78],[87],[85],[70],[81],[88],[84]])\n",
        "\n",
        "optimizer = optim.SGD([W1,W2,W3,W4,b1],lr=0.000001)\n",
        "\n",
        "test_GPA = 3.3\n",
        "test_TOEIC = 700\n",
        "test_Award = 77\n",
        "test_Etc = 84\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "  hypothesis = x_GPA * W1 + x_TOEIC * W2 + x_Award * W3 + x_Etc * W4 + b1\n",
        "  cost = torch.mean((hypothesis-y_train)**2)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  print('Epoch:%d cost: %f'%(epoch,cost))\n",
        "\n",
        "\n",
        "# test\n",
        "print('\\n')\n",
        "print(W1,W2,W3,W4)\n",
        "print(b1)\n",
        "predict = test_GPA * W1 + test_TOEIC * W2 + test_Award * W3 + test_Etc * W4 + b1\n",
        "print('Final score is estimated as %d' % (predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDuCXhIff-GR",
        "outputId": "c9a66676-2067-4d7b-defe-c1bcdc38b94d"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:0 cost: 6751.555664\n",
            "Epoch:1 cost: 667.196106\n",
            "Epoch:2 cost: 288.741180\n",
            "Epoch:3 cost: 264.421692\n",
            "Epoch:4 cost: 262.084229\n",
            "Epoch:5 cost: 261.113892\n",
            "Epoch:6 cost: 260.231293\n",
            "Epoch:7 cost: 259.356873\n",
            "Epoch:8 cost: 258.486084\n",
            "Epoch:9 cost: 257.618134\n",
            "\n",
            "\n",
            "tensor([0.0006], requires_grad=True) tensor([0.1004], requires_grad=True) tensor([0.0165], requires_grad=True) tensor([0.0105], requires_grad=True)\n",
            "tensor([0.0002], requires_grad=True)\n",
            "Final score is estimated as 72\n"
          ]
        }
      ]
    }
  ]
}