{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/champsleague/DeepLearning/blob/main/DL_Lab07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "Og4ASBkUd4eY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3285bc04-15ed-40b0-cd22-2585ed2f730e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "z-Z39U1iV9wW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class myRNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super(myRNN, self).__init__()\n",
        "\n",
        "    self.input_size = input_size # length of one-hot encoding vector\n",
        "    self.hidden_size = hidden_size # hidden state size which is determined by a designer\n",
        "    self.output_size = output_size # length of on-hot encoding vector\n",
        "   \n",
        "    # U, W, V are implemented by fully-connected layers\n",
        "    self.U = nn.Linear(input_size, hidden_size)\n",
        "    self.W = nn.Linear(hidden_size, hidden_size)\n",
        "    self.V = nn.Linear(hidden_size, output_size)\n",
        "    \n",
        "    self.activation_func = nn.Tanh() # activation cuntion = tanh \n",
        "    self.softmax = nn.LogSoftmax(dim=0) # Softmax function contains Cross-Entropy Loss\n",
        "\n",
        "  def forward(self, input, hidden):\n",
        "    hidden = self.activation_func(self.U(input) + self.W(hidden)) # ht = tanh(U*xt + W*ht+1)\n",
        "    output = self.V(hidden) # softmax(V*ht)\n",
        "    return output, hidden\n",
        "    \n",
        "  def init_hidden(self):\n",
        "    return torch.zeros(1, self.hidden_size) # initialization of the first hidden values "
      ],
      "metadata": {
        "id": "ZfkCGlQ7WJMI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define character list as the string type \n",
        "chars = \"abcdefghijklmnopqrstuvwxyz .,:;?01\" # index 0123456 .......\n",
        "\n",
        "# convert character list to list type\n",
        "char_list = [i for i in chars] \n",
        "\n",
        "# get the length of character list\n",
        "n_letters = len(char_list)"
      ],
      "metadata": {
        "id": "vi_6H3CtWUXT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For Input \n",
        "def word_to_onehot(string):\n",
        "  # we will use start and end code by using 0, 1\n",
        "  start = np.zeros(shape=len(char_list), dtype=int)\n",
        "  end = np.zeros(shape=len(char_list), dtype=int)\n",
        "  start[-2] = 1\n",
        "  end[-1] = 1\n",
        "  \n",
        "  for i in string:\n",
        "  # one-hot encoding of training string will be located between start and end vector\n",
        "    idx = char_list.index(i)\n",
        "    zero = np.zeros(shape=n_letters, dtype=int)\n",
        "    zero[idx] = 1\n",
        "    start = np.vstack([start, zero])\n",
        "  output = np.vstack([start, end])\n",
        "  return output"
      ],
      "metadata": {
        "id": "qey-V262dNOx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For Output / Test \n",
        "def onehot_to_word(onehot_1): \n",
        "  onehot = torch.Tensor.numpy(onehot_1)\n",
        "  return char_list[onehot.argmax()]"
      ],
      "metadata": {
        "id": "csWneOtLdoJ7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  n_hidden = 128 # set hidden size 128 \n",
        "  lr = 0.0001 # set learning rate to 0.001 \n",
        "  epochs = 10000 # set epochs to 1000 (5000)\n",
        "  \n",
        "  # set training string\n",
        "  # < Question 1 > \n",
        "  # string = \"i want to go on a trip these days. how about you?\"\n",
        "  \n",
        "  # < Question 2 > \n",
        "  string = \"i want to go on a trip these days. how about you? i would like to visit france, italy, germany again with my friends.\"\n",
        "  \n",
        "  # initiate RNN\n",
        "  rnn = myRNN(n_letters, n_hidden, n_letters)\n",
        "   \n",
        "  loss_func = nn.CrossEntropyLoss()  # use Cross-Entropy Loss as loss function \n",
        "  optimizer = torch.optim.Adam(rnn.parameters(), lr=lr) # Adam optimizer \n",
        "  \n",
        "  ## Training \n",
        "  one_hot = torch.from_numpy(word_to_onehot(string)).type_as(torch.FloatTensor())\n",
        "  \n",
        "  for i in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    total_loss = 0\n",
        "    hidden = rnn.init_hidden()\n",
        "    \n",
        "    input_ = one_hot[0:1, :]\n",
        "    \n",
        "    for j in range(one_hot.size()[0]-1):\n",
        "      target = one_hot[j+1]\n",
        "      target_single = torch.from_numpy(np.asarray(target.numpy().argmax())).type_as(torch.LongTensor()).view(-1)\n",
        "      \n",
        "      output, hidden = rnn.forward(input_, hidden)\n",
        "      loss = loss_func(output, target_single)\n",
        "      total_loss += loss\n",
        "      input_ = output\n",
        "    \n",
        "    total_loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if i%100 == 0:\n",
        "      print('epoch%d'%i)\n",
        "      print(total_loss)\n",
        "       \n",
        "  ## Test\n",
        "  start = torch.zeros(1, len(char_list))\n",
        "  start[:,-2] = 1\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    hidden = rnn.init_hidden()\n",
        "    input_ = start\n",
        "    output_string = \"\"\n",
        "    \n",
        "    for i in range(len(string)):\n",
        "      output, hidden = rnn.forward(input_, hidden)\n",
        "      output_string += onehot_to_word(F.softmax(output.data))\n",
        "      input_ = output\n",
        "      \n",
        "    print(output_string)\n"
      ],
      "metadata": {
        "id": "vRbWmhz2e6nb"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run the code"
      ],
      "metadata": {
        "id": "mWCWHwgPrA7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0snEiNJKn9RI",
        "outputId": "55a7e33f-0288-41aa-cf79-4850b2b55b91"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch0\n",
            "tensor(415.5131, grad_fn=<AddBackward0>)\n",
            "epoch100\n",
            "tensor(352.6122, grad_fn=<AddBackward0>)\n",
            "epoch200\n",
            "tensor(346.2035, grad_fn=<AddBackward0>)\n",
            "epoch300\n",
            "tensor(343.4576, grad_fn=<AddBackward0>)\n",
            "epoch400\n",
            "tensor(339.4114, grad_fn=<AddBackward0>)\n",
            "epoch500\n",
            "tensor(334.4246, grad_fn=<AddBackward0>)\n",
            "epoch600\n",
            "tensor(327.3868, grad_fn=<AddBackward0>)\n",
            "epoch700\n",
            "tensor(322.9275, grad_fn=<AddBackward0>)\n",
            "epoch800\n",
            "tensor(317.8551, grad_fn=<AddBackward0>)\n",
            "epoch900\n",
            "tensor(313.3098, grad_fn=<AddBackward0>)\n",
            "epoch1000\n",
            "tensor(308.5993, grad_fn=<AddBackward0>)\n",
            "epoch1100\n",
            "tensor(328.3262, grad_fn=<AddBackward0>)\n",
            "epoch1200\n",
            "tensor(311.1369, grad_fn=<AddBackward0>)\n",
            "epoch1300\n",
            "tensor(307.5543, grad_fn=<AddBackward0>)\n",
            "epoch1400\n",
            "tensor(304.2137, grad_fn=<AddBackward0>)\n",
            "epoch1500\n",
            "tensor(301.9839, grad_fn=<AddBackward0>)\n",
            "epoch1600\n",
            "tensor(299.7937, grad_fn=<AddBackward0>)\n",
            "epoch1700\n",
            "tensor(297.6776, grad_fn=<AddBackward0>)\n",
            "epoch1800\n",
            "tensor(295.4466, grad_fn=<AddBackward0>)\n",
            "epoch1900\n",
            "tensor(293.1254, grad_fn=<AddBackward0>)\n",
            "epoch2000\n",
            "tensor(290.7239, grad_fn=<AddBackward0>)\n",
            "epoch2100\n",
            "tensor(288.1864, grad_fn=<AddBackward0>)\n",
            "epoch2200\n",
            "tensor(285.5417, grad_fn=<AddBackward0>)\n",
            "epoch2300\n",
            "tensor(282.6573, grad_fn=<AddBackward0>)\n",
            "epoch2400\n",
            "tensor(279.7229, grad_fn=<AddBackward0>)\n",
            "epoch2500\n",
            "tensor(276.8887, grad_fn=<AddBackward0>)\n",
            "epoch2600\n",
            "tensor(273.9776, grad_fn=<AddBackward0>)\n",
            "epoch2700\n",
            "tensor(270.0563, grad_fn=<AddBackward0>)\n",
            "epoch2800\n",
            "tensor(265.6241, grad_fn=<AddBackward0>)\n",
            "epoch2900\n",
            "tensor(260.8950, grad_fn=<AddBackward0>)\n",
            "epoch3000\n",
            "tensor(257.1594, grad_fn=<AddBackward0>)\n",
            "epoch3100\n",
            "tensor(254.5779, grad_fn=<AddBackward0>)\n",
            "epoch3200\n",
            "tensor(253.3660, grad_fn=<AddBackward0>)\n",
            "epoch3300\n",
            "tensor(246.6331, grad_fn=<AddBackward0>)\n",
            "epoch3400\n",
            "tensor(243.2694, grad_fn=<AddBackward0>)\n",
            "epoch3500\n",
            "tensor(240.6523, grad_fn=<AddBackward0>)\n",
            "epoch3600\n",
            "tensor(236.8955, grad_fn=<AddBackward0>)\n",
            "epoch3700\n",
            "tensor(233.2886, grad_fn=<AddBackward0>)\n",
            "epoch3800\n",
            "tensor(229.5440, grad_fn=<AddBackward0>)\n",
            "epoch3900\n",
            "tensor(225.5636, grad_fn=<AddBackward0>)\n",
            "epoch4000\n",
            "tensor(221.3965, grad_fn=<AddBackward0>)\n",
            "epoch4100\n",
            "tensor(322.1130, grad_fn=<AddBackward0>)\n",
            "epoch4200\n",
            "tensor(220.1507, grad_fn=<AddBackward0>)\n",
            "epoch4300\n",
            "tensor(216.3105, grad_fn=<AddBackward0>)\n",
            "epoch4400\n",
            "tensor(213.6246, grad_fn=<AddBackward0>)\n",
            "epoch4500\n",
            "tensor(211.0705, grad_fn=<AddBackward0>)\n",
            "epoch4600\n",
            "tensor(208.4696, grad_fn=<AddBackward0>)\n",
            "epoch4700\n",
            "tensor(205.7465, grad_fn=<AddBackward0>)\n",
            "epoch4800\n",
            "tensor(203.0892, grad_fn=<AddBackward0>)\n",
            "epoch4900\n",
            "tensor(200.1607, grad_fn=<AddBackward0>)\n",
            "epoch5000\n",
            "tensor(197.4368, grad_fn=<AddBackward0>)\n",
            "epoch5100\n",
            "tensor(194.9792, grad_fn=<AddBackward0>)\n",
            "epoch5200\n",
            "tensor(192.6708, grad_fn=<AddBackward0>)\n",
            "epoch5300\n",
            "tensor(189.9193, grad_fn=<AddBackward0>)\n",
            "epoch5400\n",
            "tensor(328.1734, grad_fn=<AddBackward0>)\n",
            "epoch5500\n",
            "tensor(324.0177, grad_fn=<AddBackward0>)\n",
            "epoch5600\n",
            "tensor(312.1257, grad_fn=<AddBackward0>)\n",
            "epoch5700\n",
            "tensor(308.2147, grad_fn=<AddBackward0>)\n",
            "epoch5800\n",
            "tensor(305.3743, grad_fn=<AddBackward0>)\n",
            "epoch5900\n",
            "tensor(302.7552, grad_fn=<AddBackward0>)\n",
            "epoch6000\n",
            "tensor(299.7906, grad_fn=<AddBackward0>)\n",
            "epoch6100\n",
            "tensor(293.4505, grad_fn=<AddBackward0>)\n",
            "epoch6200\n",
            "tensor(290.1376, grad_fn=<AddBackward0>)\n",
            "epoch6300\n",
            "tensor(292.9536, grad_fn=<AddBackward0>)\n",
            "epoch6400\n",
            "tensor(284.7323, grad_fn=<AddBackward0>)\n",
            "epoch6500\n",
            "tensor(290.3311, grad_fn=<AddBackward0>)\n",
            "epoch6600\n",
            "tensor(279.7090, grad_fn=<AddBackward0>)\n",
            "epoch6700\n",
            "tensor(318.4903, grad_fn=<AddBackward0>)\n",
            "epoch6800\n",
            "tensor(311.6494, grad_fn=<AddBackward0>)\n",
            "epoch6900\n",
            "tensor(293.1292, grad_fn=<AddBackward0>)\n",
            "epoch7000\n",
            "tensor(286.5202, grad_fn=<AddBackward0>)\n",
            "epoch7100\n",
            "tensor(283.9402, grad_fn=<AddBackward0>)\n",
            "epoch7200\n",
            "tensor(281.6123, grad_fn=<AddBackward0>)\n",
            "epoch7300\n",
            "tensor(281.7680, grad_fn=<AddBackward0>)\n",
            "epoch7400\n",
            "tensor(278.7459, grad_fn=<AddBackward0>)\n",
            "epoch7500\n",
            "tensor(271.6328, grad_fn=<AddBackward0>)\n",
            "epoch7600\n",
            "tensor(263.0477, grad_fn=<AddBackward0>)\n",
            "epoch7700\n",
            "tensor(307.4878, grad_fn=<AddBackward0>)\n",
            "epoch7800\n",
            "tensor(303.4724, grad_fn=<AddBackward0>)\n",
            "epoch7900\n",
            "tensor(302.5443, grad_fn=<AddBackward0>)\n",
            "epoch8000\n",
            "tensor(306.8266, grad_fn=<AddBackward0>)\n",
            "epoch8100\n",
            "tensor(282.9239, grad_fn=<AddBackward0>)\n",
            "epoch8200\n",
            "tensor(315.4654, grad_fn=<AddBackward0>)\n",
            "epoch8300\n",
            "tensor(283.3943, grad_fn=<AddBackward0>)\n",
            "epoch8400\n",
            "tensor(253.7556, grad_fn=<AddBackward0>)\n",
            "epoch8500\n",
            "tensor(254.3652, grad_fn=<AddBackward0>)\n",
            "epoch8600\n",
            "tensor(244.9487, grad_fn=<AddBackward0>)\n",
            "epoch8700\n",
            "tensor(240.4193, grad_fn=<AddBackward0>)\n",
            "epoch8800\n",
            "tensor(236.7169, grad_fn=<AddBackward0>)\n",
            "epoch8900\n",
            "tensor(233.9804, grad_fn=<AddBackward0>)\n",
            "epoch9000\n",
            "tensor(230.0088, grad_fn=<AddBackward0>)\n",
            "epoch9100\n",
            "tensor(222.4108, grad_fn=<AddBackward0>)\n",
            "epoch9200\n",
            "tensor(215.9449, grad_fn=<AddBackward0>)\n",
            "epoch9300\n",
            "tensor(213.4871, grad_fn=<AddBackward0>)\n",
            "epoch9400\n",
            "tensor(211.7225, grad_fn=<AddBackward0>)\n",
            "epoch9500\n",
            "tensor(210.2480, grad_fn=<AddBackward0>)\n",
            "epoch9600\n",
            "tensor(208.9014, grad_fn=<AddBackward0>)\n",
            "epoch9700\n",
            "tensor(207.5352, grad_fn=<AddBackward0>)\n",
            "epoch9800\n",
            "tensor(205.9224, grad_fn=<AddBackward0>)\n",
            "epoch9900\n",
            "tensor(202.7659, grad_fn=<AddBackward0>)\n",
            "i want to go on a trpp these days. how aaou  roue   aauu  ioon   iaans  iiann   iiann   iaans  iiann   iiann   iaans \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-ba750b53b944>:56: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output_string += onehot_to_word(F.softmax(output.data))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Result Analysis\n",
        "\n",
        "GT = i want to go on a trip theses days. how about you?\n",
        "\n",
        "How can we improve the performace ? \n"
      ],
      "metadata": {
        "id": "f-eP0j3_i76j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Try many other options"
      ],
      "metadata": {
        "id": "JATUfqrjqtdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# increase number of hidden layer \n",
        "n_hidden = 256 \n",
        "\n",
        "# increase epochs\n",
        "epochs = 5000 \n",
        "\n",
        "# etc... "
      ],
      "metadata": {
        "id": "HB575qghqd0g"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}